{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[8]LSTM",
      "provenance": [],
      "authorship_tag": "ABX9TyOsdU6XtAh7ggVyvsw2DASP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doyeo-n/-Capstone-8_code/blob/main/%5B8%5DLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGT6JpISdbLH"
      },
      "outputs": [],
      "source": [
        "def splitdataset(data, timestep):\n",
        "  from array import array\n",
        "  data = data.set_index(index_col)\n",
        "  sha = data.shape\n",
        "  a = round(sha[0]*0.3)\n",
        "  b = len(data[:-a])\n",
        "  c = b%7\n",
        "  d = len(data[-a : -6])\n",
        "  e = d%7\n",
        "\n",
        "  train, test = data[c:-a], data[-a+e:-(timestep-1)] \n",
        "  return train, test\n",
        "\n",
        "def split_dataset(data, timestep):\n",
        "  train, test = splitdataset(data, timestep = 7)\n",
        "  train = array(split(train, int(len(train)/timestep)))\n",
        "  test = array(split(test, len(test)/timestep))\n",
        "  return train, test\n",
        " \n",
        "# evaluate one or more weekly forecasts against expected values\n",
        "def evaluate_forecasts(actual, predicted):\n",
        "\tscores = list()\n",
        "\t# calculate an RMSE score for each day\n",
        "\tfor i in range(actual.shape[1]):\n",
        "\t\t# calculate mse\n",
        "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
        "\t\t# calculate rmse\n",
        "\t\trmse = sqrt(mse)\n",
        "\t\t# store\n",
        "\t\tscores.append(rmse)\n",
        "\t# calculate overall RMSE\n",
        "\ts = 0\n",
        "\tfor row in range(actual.shape[0]):\n",
        "\t\tfor col in range(actual.shape[1]):\n",
        "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
        "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
        "\treturn score, scores\n",
        "\n",
        "# convert history into inputs and outputs\n",
        "def to_supervised(train, n_input, n_out=7):\n",
        "\t# flatten data\n",
        "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
        "\tX, y = list(), list()\n",
        "\tin_start = 0\n",
        "\t# step over the entire history one time step at a time\n",
        "\tfor _ in range(len(data)):\n",
        "\t\t# define the end of the input sequence\n",
        "\t\tin_end = in_start + n_input\n",
        "\t\tout_end = in_end + n_out\n",
        "\t\t# ensure we have enough data for this instance\n",
        "\t\tif out_end <= len(data):\n",
        "\t\t\tX.append(data[in_start:in_end, :])\n",
        "\t\t\ty.append(data[in_end:out_end, -1])\n",
        "\t\t# move along one time step\n",
        "\t\tin_start += 1\n",
        "\treturn array(X), array(y)\n",
        "\n",
        "# train the model\n",
        "def build_model(train, n_input):\n",
        "\t# prepare data\n",
        "\ttrain_x, train_y = to_supervised(train, n_input)\n",
        "\n",
        "\t# define parameters\n",
        "\tverbose, epochs, batch_size = verbose_a, epochs_a, batch_size_a\n",
        "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
        "\t# reshape output into [samples, timesteps, features]\n",
        "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
        " \n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(LSTM(200, activation='relu', input_shape=(n_timesteps, n_features)))\n",
        "\tmodel.add(RepeatVector(n_outputs))\n",
        "\tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n",
        "\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
        "\tmodel.add(TimeDistributed(Dense(1)))\n",
        "\tmodel.compile(loss='mse', optimizer='adam')\n",
        "                         \n",
        "\t# fit network\n",
        "\tmodel.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\treturn model\n",
        "\n",
        "# make a forecast\n",
        "def forecast(model, history, n_input):\n",
        "\t# flatten data\n",
        "\tdata = array(history)\n",
        "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
        "\t# retrieve last observations for input data\n",
        "\tinput_x = data[-n_input:, :]\n",
        "\t# reshape into [1, n_input, n]\n",
        "\tinput_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
        "\t# forecast the next week\n",
        "\tyhat = model.predict(input_x, verbose=0)\n",
        "\t# we only want the vector forecast\n",
        "\tyhat = yhat[0]\n",
        "\treturn yhat\n",
        "\n",
        "\n",
        "def evaluate_model(train, test, n_input):\n",
        "\t# fit model\n",
        "\tmodel = build_model(train, n_input)\n",
        " \n",
        "\t# history is a list of weekly data\n",
        "\thistory = [x for x in train]\n",
        "\n",
        "\t# walk-forward validation over each week\n",
        "\tpredictions = list()\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# predict the week\n",
        "\t\tyhat_sequence = forecast(model, history, n_input)\n",
        "\t\t# store the predictions\n",
        "\t\tpredictions.append(yhat_sequence)\n",
        "\t\t# get real observation and add to history for predicting the next week\n",
        "\t\thistory.append(test[i, :])\n",
        "\t# evaluate predictions days for each week\n",
        "\tpredictions = array(predictions)\n",
        "\t#score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
        "\tscore, scores = evaluate_forecasts(test[:, :, -1], predictions)\n",
        "\treturn  model, score, scores, predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#result\n",
        "def rmse_plot():\n",
        "  days = ['D+1', 'D+2', 'D+3', 'D+4', 'D+5', 'D+6', 'D+7']\n",
        "  pyplot.plot(days, scores, marker='o', label='lstm')\n",
        "  pyplot.show()\n",
        "\n",
        "def comparison():\n",
        "  #실제값\n",
        "  da_test = test[-1,:,-1]\n",
        "  #예측값\n",
        "  da_pred = predictions[-1]\n",
        "\n",
        "  da_test = pd.DataFrame(da_test)\n",
        "  da_pred = pd.DataFrame(da_pred)\n",
        "  data_f = concat([da_test, da_pred], axis=1)\n",
        "  list_a = ['d+1', 'd+2', 'd+3', 'd+4', 'd+5', 'd+6', \"d+7\"]\n",
        "  list_a = pd.DataFrame(list_a)\n",
        "  data_f = concat([data_f, list_a], axis=1)\n",
        "  data_f.columns = ['test', 'pred', 'index']\n",
        "  data_f = data_f.set_index('index')\n",
        "  data_f\n",
        "  return data_f\n",
        "\n",
        "def plot_3(imputed_data):\n",
        "  p = np.ravel(predictions)\n",
        "  t = np.ravel(test[:,:,-1])\n",
        "  data_kalman= imputed_data\n",
        "  data_kalman = data_kalman.set_index('date')\n",
        "\n",
        "  original['masking'] = 1\n",
        "  mask = original['masking']\n",
        "  mask.columns = ['masking']\n",
        "  #df_new['date-like_column'] = pd.to_datetime(df_new['date-like-column']\n",
        "  data_mask = pd.merge(imputed_data, mask,left_index=True, right_index=True, how='left')\n",
        "  data_mask[(data_mask['masking']=='NaN')]=0\n",
        "\n",
        "  data_mask['masking'] = data_mask['masking'].fillna(0)\n",
        "\n",
        "  data_mask = data_mask.iloc[-916:, :]\n",
        "  data_mask['log_cyan'][(data_mask['masking']==0)] = np.nan\n",
        "  rea_y = np.array(data_mask['log_cyan'])\n",
        "  print(len(rea_y))\n",
        "\n",
        "  #실제값/예측값\n",
        "  pyplot.figure(figsize=(15, 10))\n",
        "  #pyplot.plot(inv_y, 'ko')\n",
        "  pyplot.plot(p, 'r.-')\n",
        "  pyplot.plot(rea_y, 'ko')\n",
        "  pyplot.legend([\"Pred\", \"Obs\"], bbox_to_anchor = (1,1) )\n",
        "  pyplot.show()\n",
        "\n",
        "  #임퓨테이션한 값/ 예측값\n",
        "  pyplot.figure(figsize=(15, 10))\n",
        "  pyplot.plot(t)\n",
        "  pyplot.plot(p)\n",
        "\n",
        "  pyplot.legend([\"Obs\", \"Pred\"], bbox_to_anchor = (1,1) )\n",
        "  pyplot.show()\n",
        "\n",
        "  #one-to-one plot\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.scatter(t, p, color = 'red')\n",
        "  lims = [np.min([0, 15]), np.max([0, 15])]\n",
        "  plt.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
        "  plt.xlim(lims)\n",
        "  plt.ylim(lims)\n",
        "  plt.xlabel(\"real\")\n",
        "  plt.ylabel(\"predicted\")\n",
        "  plt.show()\n",
        "\n",
        "  import gc\n",
        "  gc.collect()\n",
        "  \"\"\"\n",
        "  print(inv_yhat.shape)\n",
        "  print(inv_y.shape)\n",
        "  \"\"\"\n",
        "def classification(predictions, test):\n",
        "  pred = predictions.flatten()\n",
        "  true = test[:,:,-1].flatten()\n",
        "  pred = pd.DataFrame(pred)\n",
        "  true = pd.DataFrame(true)\n",
        "  pred['class'] = np.nan\n",
        "  true['class'] = np.nan\n",
        "\n",
        "  math.log(784)\n",
        "  a = math.log(1000)\n",
        "  b = math.log(10000)\n",
        "  c = math.log(1000000)\n",
        "\n",
        "  for i in range (len(pred)):\n",
        "    if pred.iloc[i,0] < a :\n",
        "      pred.iloc[i,1] = 0\n",
        "    elif a <= pred.iloc[i,0] <b :\n",
        "      pred.iloc[i,1] = 1\n",
        "    elif b<= pred.iloc[i,0] < c:\n",
        "      pred.iloc[i,1] = 2\n",
        "    elif c<= pred.iloc[i,0]:\n",
        "      pred.iloc[i,1] = 3\n",
        "    else:\n",
        "      pred.iloc[i,1] = 999\n",
        "\n",
        "\n",
        "  for i in range (len(true)):\n",
        "    if true.iloc[i,0] < a :\n",
        "      true.iloc[i,1] = 0\n",
        "    elif a <= true.iloc[i,0] <b :\n",
        "      true.iloc[i,1] = 1\n",
        "    elif b<= true.iloc[i,0] < c:\n",
        "      true.iloc[i,1] = 2\n",
        "    elif c<= true.iloc[i,0]:\n",
        "      true.iloc[i,1] = 3\n",
        "    else:\n",
        "      true.iloc[i,1] = 999\n",
        "\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  acc_test = accuracy_score(true['class'], pred['class'])\n",
        "  print(acc_test)\n",
        "  from sklearn.metrics import classification_report, confusion_matrix\n",
        "  print(classification_report(true['class'], pred['class']))\n",
        "  print(confusion_matrix(true['class'], pred['class']))\n",
        "\n",
        "#test 중 실제값이 있는 데이터에 한해 분류 성능 평가\n",
        "def test_classification(predcitions, test):\n",
        "  df_m = eutrophication.iloc[1:,:]\n",
        "  data=df_m\n",
        "  train, test_m = data[1:-916], data[-916:-6]\n",
        "  train = array(split(train, int(len(train)/7)))\n",
        "  test_m = array(split(test_m, len(test_m)/7))\n",
        "  print(train.shape, test_m.shape)\n",
        "\n",
        "  print(test_m[:,:,-1].shape, predictions.shape)\n",
        "\n",
        "  pred = predictions.flatten()\n",
        "  true_m = test_m[:,:,-1].flatten()\n",
        "  true_m = pd.DataFrame(true_m)\n",
        "  pred = pd.DataFrame(pred)\n",
        "\n",
        "  da = pd.concat([true_m, pred], axis=1)\n",
        "\n",
        "  da.columns = ['true', 'pred']\n",
        "  da = da.dropna()\n",
        "\n",
        "  true_m = da['true']\n",
        "  pred = da['pred']\n",
        "  pred = pd.DataFrame(pred)\n",
        "  true_m = pd.DataFrame(true_m)\n",
        "  pred['class'] = 'nan'\n",
        "  true_m['class']='nan'\n",
        "\n",
        "  import math\n",
        "  math.log(784)\n",
        "  a = math.log(1000)\n",
        "  b = math.log(10000)\n",
        "  c = math.log(1000000)\n",
        "\n",
        "  pred = pred.reset_index(drop=True, inplace=False)\n",
        "  true_m = true_m.reset_index(drop=True, inplace=False)\n",
        "\n",
        "  for i in range (len(pred)):\n",
        "    if pred.iloc[i,0] < a :\n",
        "      pred.iloc[i,1] = 0\n",
        "    elif a <= pred.iloc[i,0] <b :\n",
        "      pred.iloc[i,1] = 1\n",
        "    elif b<= pred.iloc[i,0] < c:\n",
        "      pred.iloc[i,1] = 2\n",
        "    elif c<= pred.iloc[i,0]:\n",
        "      pred.iloc[i,1] = 3\n",
        "    else:\n",
        "      pred.iloc[i,1] = 999\n",
        "\n",
        "\n",
        "  for i in range (len(true_m)):\n",
        "    if true_m.iloc[i,0] < a :\n",
        "      true_m.iloc[i,1] = 0\n",
        "    elif a <= true_m.iloc[i,0] <b :\n",
        "      true_m.iloc[i,1] = 1\n",
        "    elif b<= true_m.iloc[i,0] < c:\n",
        "      true_m.iloc[i,1] = 2\n",
        "    elif c<= true_m.iloc[i,0]:\n",
        "      true_m.iloc[i,1] = 3\n",
        "    else:\n",
        "      true_m.iloc[i,1] = 999\n",
        "\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "  true_new = true_m.iloc[:,1].tolist()\n",
        "  pred_new = pred.iloc[:,1].tolist()\n",
        "\n",
        "  acc_test = accuracy_score(true_new, pred_new)\n",
        "  print(acc_test)\n",
        "\n",
        "  print(classification_report(true_new, pred_new))\n",
        "  print(confusion_matrix(true_new, pred_new))\n"
      ],
      "metadata": {
        "id": "LGoN43uldeHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#결정사항\n",
        "verbose_a, epochs_a, batch_size_a=1, 10, 1\n",
        "timestep = 7\n",
        "\n",
        "#LSTM 모델링\n",
        "train, test = split_dataset(imputed_data, timestep)\n",
        "model, score, scores, predictions = evaluate_model(train, test, n_input)\n",
        "\n",
        "#LSTM 모델링 결과 확인\n",
        "print(f'test 전체 rmse : {score}, 마지막 7일에 대한 각각의 rmse : {score}')\n",
        "rmse_plot()\n",
        "\n",
        "comparison()\n",
        "\n",
        "plot_3(imputed_data)\n",
        "\n",
        "print('test 데이터에 대한 분류 혼동행렬')\n",
        "classification(predictions, test)\n",
        "print('test 데이터 중 실제 존재하는 값에 대한 분류 혼동행렬')\n",
        "test_classification(predictions, test)"
      ],
      "metadata": {
        "id": "fJJbst45deze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}